<h1 align="center">ğŸ”€ FlowMesh</h1>
<p align="center">
  <strong>A distributed task orchestration engine with DAG-based scheduling, resilience patterns, and async-first execution.</strong>
</p>

<p align="center">
  <img alt="Python 3.11+" src="https://img.shields.io/badge/python-3.11%2B-blue?logo=python&logoColor=white" />
  <img alt="Test coverage" src="https://img.shields.io/badge/coverage-95%25-brightgreen" />
  <img alt="License" src="https://img.shields.io/badge/license-MIT-green" />
  <img alt="CI" src="https://img.shields.io/github/actions/workflow/status/Amory199/fuzzy-octo-train/ci.yml?label=CI" />
</p>

---

## Overview

FlowMesh is a **production-grade workflow engine** built from the ground up in Python. It lets you define complex task pipelines as directed acyclic graphs (DAGs), executes them asynchronously with full dependency resolution, and protects downstream services using battle-tested resilience patterns.

### Key Features

| Feature | Description |
|---|---|
| **DAG-based scheduling** | Topological sort (Kahn's algorithm) ensures tasks run in valid dependency order |
| **Async execution engine** | `asyncio`-native with configurable concurrency via semaphore |
| **Circuit Breaker** | Three-state fault isolation (Closed â†’ Open â†’ Half-Open) prevents cascading failures |
| **Retry with backoff** | Exponential backoff with jitter for transient failure recovery |
| **Token-bucket rate limiter** | Protects downstream services from burst traffic |
| **Event-driven architecture** | Pub/sub event bus for decoupled lifecycle observation |
| **REST API** | FastAPI-powered HTTP interface with OpenAPI docs |
| **Pluggable storage** | Hexagonal architecture â€” swap in Redis, Postgres, etc. |
| **95% test coverage** | Unit + integration tests with pytest-asyncio |
| **Docker-ready** | Multi-stage Dockerfile with health checks |
| **CI/CD** | GitHub Actions pipeline with lint, test, type-check, and Docker build |

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     REST API (FastAPI)                    â”‚
â”‚              POST /workflows  GET /workflows             â”‚
â”‚              GET /health      GET /stats                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Execution Engine                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   DAG   â”‚  â”‚ Scheduler â”‚  â”‚     Event Bus          â”‚ â”‚
â”‚  â”‚ (topo-  â”‚  â”‚ (concurr- â”‚  â”‚ (pub/sub lifecycle     â”‚ â”‚
â”‚  â”‚  sort)  â”‚  â”‚  ency)    â”‚  â”‚  events)               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Resilience Layer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Circuit Breaker  â”‚  Retry + Backoff  â”‚ Rate Limit â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Storage Layer                           â”‚
â”‚     InMemoryStore  â”‚  (Redis)  â”‚  (PostgreSQL)           â”‚
â”‚        âœ… built-in â”‚  ğŸ”Œ plug  â”‚  ğŸ”Œ plug               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Quick Start

### Installation

```bash
# Clone and install
git clone https://github.com/Amory199/fuzzy-octo-train.git
cd fuzzy-octo-train
pip install -e ".[dev]"
```

### Run the Example

```bash
python examples/basic_workflow.py
```

Output:
```
ğŸ“¥ Extracted 1,000 records
âœ… Validated schema
ğŸ”„ Transformed records    â† runs in parallel with enrich
ğŸ§¬ Enriched with external data
ğŸ“¤ Loaded into data warehouse
ğŸ”” Sent completion notification

â”€â”€ Results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  extract:   success  (201ms)
  validate:  success  (100ms)
  transform: success  (301ms)
  enrich:    success  (151ms)
  load:      success  (200ms)
  notify:    success  (50ms)

Workflow status: success
```

### Start the API Server

```bash
# Development
uvicorn flowmesh.api.app:create_app --factory --reload

# Production (Docker)
docker compose up -d
```

Then open **http://localhost:8000/docs** for interactive API documentation.

---

## Usage

### Define a Workflow

```python
import asyncio
from flowmesh.core.engine import ExecutionEngine
from flowmesh.core.models import Task, Workflow

async def extract():
    # your extraction logic
    return {"records": 1000}

async def transform():
    return {"transformed": True}

async def load():
    return {"loaded": True}

workflow = Workflow(
    name="ETL Pipeline",
    tasks=[
        Task(name="extract", func=extract),
        Task(name="transform", func=transform, depends_on=["extract"]),
        Task(name="load", func=load, depends_on=["transform"]),
    ],
)

engine = ExecutionEngine()
results = asyncio.run(engine.execute(workflow))
```

### Add Resilience

```python
from flowmesh.patterns.circuit_breaker import CircuitBreaker, CircuitBreakerConfig
from flowmesh.patterns.retry import RetryPolicy

cb = CircuitBreaker(CircuitBreakerConfig(failure_threshold=5, recovery_timeout_seconds=30))
retry = RetryPolicy(max_retries=3, base_delay_seconds=0.1, jitter=True)

engine = ExecutionEngine(circuit_breaker=cb, default_retry=retry)
```

### Subscribe to Events

```python
from flowmesh.core.events import EventBus, EventType

bus = EventBus()

async def on_task_complete(event):
    print(f"Task {event.payload['task_name']} finished in {event.payload['duration_ms']:.0f}ms")

bus.subscribe(EventType.TASK_COMPLETED, on_task_complete)
engine = ExecutionEngine(event_bus=bus)
```

### REST API

```bash
# Create a workflow
curl -X POST http://localhost:8000/workflows \
  -H "Content-Type: application/json" \
  -d '{
    "name": "My Pipeline",
    "tasks": [
      {"name": "step1"},
      {"name": "step2", "depends_on": ["step1"]},
      {"name": "step3", "depends_on": ["step1"]},
      {"name": "step4", "depends_on": ["step2", "step3"]}
    ]
  }'

# List all workflows
curl http://localhost:8000/workflows

# Health check
curl http://localhost:8000/health
```

---

## Design Patterns Demonstrated

| Pattern | Location | Purpose |
|---|---|---|
| **DAG + Topological Sort** | `core/models.py` | Dependency resolution via Kahn's algorithm |
| **Circuit Breaker** | `patterns/circuit_breaker.py` | Fault isolation with three-state machine |
| **Retry with Exponential Backoff** | `patterns/retry.py` | Transient failure recovery |
| **Token Bucket Rate Limiter** | `patterns/rate_limiter.py` | Throughput protection |
| **Pub/Sub Event Bus** | `core/events.py` | Decoupled lifecycle notifications |
| **Hexagonal Architecture** | `storage/base.py` | Ports-and-adapters for pluggable persistence |
| **Repository Pattern** | `storage/memory.py` | Abstracted data access |
| **Factory Pattern** | `api/app.py` | Application assembly and DI |
| **Strategy Pattern** | Engine retry/CB | Interchangeable resilience strategies |
| **Command Pattern** | `core/models.Task` | Encapsulated async callables |

---

## Development

```bash
# Install with dev dependencies
pip install -e ".[dev]"

# Run tests
pytest -v

# Run tests with coverage
pytest --cov=src/flowmesh --cov-report=term-missing

# Lint
ruff check src/ tests/

# Format
ruff format src/ tests/

# Type check
mypy src/flowmesh/
```

---

## Project Structure

```
â”œâ”€â”€ src/flowmesh/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ models.py        # Task, Workflow, DAG (Kahn's toposort)
â”‚   â”‚   â”œâ”€â”€ engine.py        # Async execution engine
â”‚   â”‚   â”œâ”€â”€ scheduler.py     # Concurrency-controlled scheduler
â”‚   â”‚   â””â”€â”€ events.py        # Pub/sub event bus
â”‚   â”œâ”€â”€ patterns/
â”‚   â”‚   â”œâ”€â”€ circuit_breaker.py
â”‚   â”‚   â”œâ”€â”€ retry.py
â”‚   â”‚   â””â”€â”€ rate_limiter.py
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ app.py           # FastAPI factory
â”‚   â”‚   â”œâ”€â”€ routes.py        # REST endpoints
â”‚   â”‚   â””â”€â”€ schemas.py       # Pydantic models
â”‚   â””â”€â”€ storage/
â”‚       â”œâ”€â”€ base.py           # Abstract store (hexagonal port)
â”‚       â””â”€â”€ memory.py         # In-memory adapter
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                 # 38 unit tests
â”‚   â””â”€â”€ integration/          # 7 API integration tests
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ basic_workflow.py
â”‚   â””â”€â”€ data_pipeline.py
â”œâ”€â”€ Dockerfile                # Multi-stage build
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ pyproject.toml            # Modern Python packaging
â””â”€â”€ .github/workflows/ci.yml  # CI pipeline
```

---

## License

MIT